{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the processed claim data\n",
    "data_path = 'ProcessedClaimData.csv'  # Update this path if necessary\n",
    "claim_data = pd.read_csv(data_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Overview:\")\n",
    "print(claim_data.info())\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(claim_data.head())\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = claim_data.isnull().sum()\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Basic statistics of numerical columns\n",
    "print(\"\\nBasic statistics of numerical columns:\")\n",
    "print(claim_data.describe())\n",
    "\n",
    "# Visualize the distribution of the target variable\n",
    "target_col = 'SettlementValue'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(claim_data[target_col], kde=True, bins=30, color='blue')\n",
    "plt.title('Distribution of Settlement Values')\n",
    "plt.xlabel('Settlement Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this after loading the data\n",
    "import numpy as np\n",
    "\n",
    "# Apply log transformation to the target variable\n",
    "claim_data['LogSettlementValue'] = np.log1p(claim_data[target_col])\n",
    "print(\"Original Settlement Value statistics:\")\n",
    "print(claim_data[target_col].describe())\n",
    "print(\"\\nLog-transformed Settlement Value statistics:\")\n",
    "print(claim_data['LogSettlementValue'].describe())\n",
    "\n",
    "# Update target column to use log-transformed values\n",
    "original_target_col = target_col\n",
    "target_col = 'LogSettlementValue'\n",
    "\n",
    "# Visualize the transformation\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(claim_data[original_target_col], kde=True, bins=30, color='blue')\n",
    "plt.title('Original Settlement Values')\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(claim_data[target_col], kde=True, bins=30, color='green')\n",
    "plt.title('Log-transformed Settlement Values')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for PyTorch\n",
    "Convert the pandas dataframe to PyTorch tensors. Handle categorical variables by encoding them appropriately. Split the data into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables and prepare data for PyTorch\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = claim_data.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = claim_data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Remove the target column from the feature list\n",
    "if target_col in numerical_cols:\n",
    "    numerical_cols.remove(target_col)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply transformations\n",
    "X = preprocessor.fit_transform(claim_data.drop(columns=[target_col]))\n",
    "y = claim_data[target_col].values\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[:, :len(numerical_cols)] = scaler.fit_transform(X[:, :len(numerical_cols)])\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_tensor, y_tensor, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create DataLoader objects for PyTorch\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Training set size: {len(train_dataset)} samples\")\n",
    "print(f\"Validation set size: {len(val_dataset)} samples\")\n",
    "print(f\"Test set size: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Neural Network Model\n",
    "Implement a simple PyTorch neural network model for regression. Design the architecture with appropriate input size, hidden layers, and output layer. Implement optimization for Apple Silicon using MPS backend if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if MPS (Metal Performance Shaders) backend is available for Apple Silicon\n",
    "device = torch.device(\"mps\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the PyTorch neural network model\n",
    "class InsuranceNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(InsuranceNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),  # Input layer to first hidden layer\n",
    "            nn.ReLU(),                 # Activation function\n",
    "            nn.Linear(64, 32),         # First hidden layer to second hidden layer\n",
    "            nn.ReLU(),                 # Activation function\n",
    "            nn.Linear(32, 1)           # Second hidden layer to output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train.shape[1]\n",
    "model = InsuranceNN(input_size).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(X_batch)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            predictions = model(X_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "predictions_list = []\n",
    "actuals_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        predictions = model(X_batch)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        test_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        predictions_list.extend(predictions.cpu().numpy())\n",
    "        actuals_list.extend(y_batch.cpu().numpy())\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(actuals_list, predictions_list, alpha=0.6)\n",
    "plt.plot([min(actuals_list), max(actuals_list)], [min(actuals_list), max(actuals_list)], 'r--')\n",
    "plt.xlabel(\"Actual Settlement Values\")\n",
    "plt.ylabel(\"Predicted Settlement Values\")\n",
    "plt.title(\"Actual vs Predicted Settlement Values\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate the Model\n",
    "Train the neural network model using the training data. Implement early stopping based on validation performance. Evaluate the model on the test set and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate the Model\n",
    "\n",
    "# Implement early stopping\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(X_batch)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            predictions = model(X_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "predictions_list = []\n",
    "actuals_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        predictions = model(X_batch)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        test_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        predictions_list.extend(predictions.cpu().numpy())\n",
    "        actuals_list.extend(y_batch.cpu().numpy())\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(actuals_list, predictions_list, alpha=0.6)\n",
    "plt.plot([min(actuals_list), max(actuals_list)], [min(actuals_list), max(actuals_list)], 'r--')\n",
    "plt.xlabel(\"Actual Settlement Values\")\n",
    "plt.ylabel(\"Predicted Settlement Values\")\n",
    "plt.title(\"Actual vs Predicted Settlement Values\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss with Early Stopping\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this after model evaluation section\n",
    "def evaluate_model_in_gbp(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model and report errors in GBP (pounds)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    actual_gbp = []\n",
    "    predicted_gbp = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            # Get predictions\n",
    "            predictions = model(X_batch)\n",
    "            \n",
    "            y_gbp = torch.expm1(y_batch).cpu().numpy()\n",
    "            pred_gbp = torch.expm1(predictions).cpu().numpy()\n",
    "            \n",
    "            actual_gbp.extend(y_gbp)\n",
    "            predicted_gbp.extend(pred_gbp)\n",
    "    \n",
    "    # Calculate error metrics in GBP\n",
    "    mse_gbp = mean_squared_error(actual_gbp, predicted_gbp)\n",
    "    rmse_gbp = np.sqrt(mse_gbp)\n",
    "    mae_gbp = mean_absolute_error(actual_gbp, predicted_gbp)\n",
    "    mape_gbp = np.mean(np.abs((np.array(actual_gbp) - np.array(predicted_gbp)) / np.array(actual_gbp))) * 100\n",
    "    \n",
    "    print(\"Errors in GBP (£):\")\n",
    "    print(f\"MSE: £{mse_gbp:.2f}\")\n",
    "    print(f\"RMSE: £{rmse_gbp:.2f}\")\n",
    "    print(f\"MAE: £{mae_gbp:.2f}\")\n",
    "    print(f\"MAPE: {mape_gbp:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'MSE_GBP': mse_gbp,\n",
    "        'RMSE_GBP': rmse_gbp,\n",
    "        'MAE_GBP': mae_gbp,\n",
    "        'MAPE_GBP': mape_gbp,\n",
    "        'actual_gbp': actual_gbp,\n",
    "        'predicted_gbp': predicted_gbp\n",
    "    }\n",
    "\n",
    "# Call this function to evaluate on test set\n",
    "gbp_metrics = evaluate_model_in_gbp(model, test_loader, device)\n",
    "\n",
    "# Visualize predictions in GBP\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(gbp_metrics['actual_gbp'], gbp_metrics['predicted_gbp'], alpha=0.5)\n",
    "plt.plot([min(gbp_metrics['actual_gbp']), max(gbp_metrics['actual_gbp'])], \n",
    "         [min(gbp_metrics['actual_gbp']), max(gbp_metrics['actual_gbp'])], 'r--')\n",
    "plt.xlabel('Actual Settlement Values (£)')\n",
    "plt.ylabel('Predicted Settlement Values (£)')\n",
    "plt.title('Actual vs Predicted Settlement Values in GBP')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_prediction_errors_gbp(actual_gbp, predicted_gbp, figsize=(12, 6), bins=50, \n",
    "                                  color='steelblue', show_plot=True, save_path=None):\n",
    "    \"\"\"\n",
    "    Analyze and visualize the errors between predicted and actual values in GBP (pounds).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    actual_gbp : array-like\n",
    "        Actual settlement values in GBP\n",
    "    predicted_gbp : array-like\n",
    "        Predicted settlement values in GBP\n",
    "    figsize : tuple, optional\n",
    "        Figure size (width, height) in inches\n",
    "    bins : int, optional\n",
    "        Number of histogram bins\n",
    "    color : str, optional\n",
    "        Color for the histogram bars\n",
    "    show_plot : bool, optional\n",
    "        Whether to display the plot\n",
    "    save_path : str, optional\n",
    "        Path to save the figure (if None, figure is not saved)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing error metrics (mean, median, std, MAE, RMSE)\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays if they aren't already\n",
    "    actual_gbp = np.array(actual_gbp).flatten()\n",
    "    predicted_gbp = np.array(predicted_gbp).flatten()\n",
    "    \n",
    "    # Calculate differences\n",
    "    differences_gbp = predicted_gbp - actual_gbp\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean_error = np.mean(differences_gbp)\n",
    "    median_error = np.median(differences_gbp)\n",
    "    std_error = np.std(differences_gbp)\n",
    "    mae = np.mean(np.abs(differences_gbp))\n",
    "    rmse = np.sqrt(np.mean(np.square(differences_gbp)))\n",
    "    mape = np.mean(np.abs(differences_gbp / actual_gbp)) * 100\n",
    "    \n",
    "    # Create a histogram of the differences\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.hist(differences_gbp, bins=bins, alpha=0.7, color=color, edgecolor='black')\n",
    "    plt.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Prediction Error (Predicted - Actual in £)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Prediction Errors in GBP')\n",
    "    \n",
    "    # Add statistics to the plot\n",
    "    stats_text = (f'Mean Error: £{mean_error:.2f}\\n'\n",
    "                  f'Median Error: £{median_error:.2f}\\n'\n",
    "                  f'MAE: £{mae:.2f}\\n'\n",
    "                  f'RMSE: £{rmse:.2f}\\n'\n",
    "                  f'MAPE: {mape:.2f}%\\n'\n",
    "                  f'Std Deviation: £{std_error:.2f}')\n",
    "    \n",
    "    plt.annotate(stats_text, xy=(0.75, 0.8), xycoords='axes fraction', \n",
    "                 bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "    \n",
    "    # Return error metrics as a dictionary\n",
    "    return {\n",
    "        'mean_error': mean_error,\n",
    "        'median_error': median_error,\n",
    "        'std_error': std_error,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'mape': mape\n",
    "    }\n",
    "\n",
    "# Example usage - add this after evaluating your model with the evaluate_model_in_gbp function\n",
    "error_metrics = analyze_prediction_errors_gbp(\n",
    "    gbp_metrics['actual_gbp'], \n",
    "    gbp_metrics['predicted_gbp']\n",
    ")\n",
    "\n",
    "print(\"Error Analysis Complete!\")\n",
    "print(f\"Mean Absolute Error (MAE): £{error_metrics['mae']:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): £{error_metrics['rmse']:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {error_metrics['mape']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with Other Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the neural network model with other models\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define and train Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train.cpu().numpy(), y_train.cpu().numpy())\n",
    "lr_predictions = lr_model.predict(X_test.cpu().numpy())\n",
    "lr_mse = mean_squared_error(y_test.cpu().numpy(), lr_predictions)\n",
    "lr_r2 = r2_score(y_test.cpu().numpy(), lr_predictions)\n",
    "\n",
    "# Define and train Ridge Regression model\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train.cpu().numpy(), y_train.cpu().numpy())\n",
    "ridge_predictions = ridge_model.predict(X_test.cpu().numpy())\n",
    "ridge_mse = mean_squared_error(y_test.cpu().numpy(), ridge_predictions)\n",
    "ridge_r2 = r2_score(y_test.cpu().numpy(), ridge_predictions)\n",
    "\n",
    "# Define and train Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "rf_model.fit(X_train.cpu().numpy(), y_train.cpu().numpy().ravel())\n",
    "rf_predictions = rf_model.predict(X_test.cpu().numpy())\n",
    "rf_mse = mean_squared_error(y_test.cpu().numpy(), rf_predictions)\n",
    "rf_r2 = r2_score(y_test.cpu().numpy(), rf_predictions)\n",
    "\n",
    "# Compare performance metrics\n",
    "models_comparison = pd.DataFrame({\n",
    "    'Model': ['Neural Network', 'Linear Regression', 'Ridge Regression', 'Random Forest'],\n",
    "    'MSE': [test_loss, lr_mse, ridge_mse, rf_mse],\n",
    "    'R^2': [r2_score(y_test.cpu().numpy(), np.array(predictions_list).flatten()), lr_r2, ridge_r2, rf_r2]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(models_comparison)\n",
    "\n",
    "# Visualize the performance metrics\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=models_comparison.melt(id_vars='Model', var_name='Metric', value_name='Value'),\n",
    "            x='Model', y='Value', hue='Metric', palette='viridis')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.xlabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Simple NLP for Accident Descriptions\n",
    "Implement a basic text processing pipeline for the accident descriptions. Use TF-IDF or simple embeddings to convert text to numerical features. Incorporate these features into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Simple NLP for Accident Descriptions\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Check if 'AccidentDescription' column exists\n",
    "if 'AccidentDescription' in claim_data.columns:\n",
    "    # Extract accident descriptions\n",
    "    accident_descriptions = claim_data['AccidentDescription'].fillna('')  # Replace NaN with empty strings\n",
    "\n",
    "    # Initialize TF-IDF Vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=100)  # Limit to top 100 features for simplicity\n",
    "\n",
    "    # Fit and transform the accident descriptions\n",
    "    tfidf_features = tfidf_vectorizer.fit_transform(accident_descriptions).toarray()\n",
    "\n",
    "    # Convert to DataFrame for easier handling\n",
    "    tfidf_df = pd.DataFrame(tfidf_features, columns=[f\"TFIDF_{i}\" for i in range(tfidf_features.shape[1])])\n",
    "\n",
    "    # Add TF-IDF features to the original dataset\n",
    "    claim_data = pd.concat([claim_data.reset_index(drop=True), tfidf_df], axis=1)\n",
    "\n",
    "    print(\"TF-IDF features added to the dataset.\")\n",
    "else:\n",
    "    print(\"Column 'AccidentDescription' not found in the dataset.\")\n",
    "\n",
    "# Update the feature set to include TF-IDF features\n",
    "tfidf_cols = [col for col in claim_data.columns if col.startswith(\"TFIDF_\")]\n",
    "X = preprocessor.fit_transform(claim_data.drop(columns=[target_col] + tfidf_cols))\n",
    "X_tfidf = claim_data[tfidf_cols].values\n",
    "\n",
    "# Combine numerical, categorical, and TF-IDF features\n",
    "X_combined = np.hstack((X, X_tfidf))\n",
    "\n",
    "# Standardize the combined features\n",
    "X_combined[:, :len(numerical_cols)] = scaler.fit_transform(X_combined[:, :len(numerical_cols)])\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor_combined = torch.tensor(X_combined, dtype=torch.float32)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train_combined, X_temp_combined, y_train, y_temp = train_test_split(X_tensor_combined, y_tensor, test_size=0.3, random_state=42)\n",
    "X_val_combined, X_test_combined, y_val, y_test = train_test_split(X_temp_combined, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create DataLoader objects for PyTorch\n",
    "train_dataset_combined = TensorDataset(X_train_combined, y_train)\n",
    "val_dataset_combined = TensorDataset(X_val_combined, y_val)\n",
    "test_dataset_combined = TensorDataset(X_test_combined, y_test)\n",
    "\n",
    "train_loader_combined = DataLoader(train_dataset_combined, batch_size=batch_size, shuffle=True)\n",
    "val_loader_combined = DataLoader(val_dataset_combined, batch_size=batch_size, shuffle=False)\n",
    "test_loader_combined = DataLoader(test_dataset_combined, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Training set size with TF-IDF: {len(train_dataset_combined)} samples\")\n",
    "print(f\"Validation set size with TF-IDF: {len(val_dataset_combined)} samples\")\n",
    "print(f\"Test set size with TF-IDF: {len(test_dataset_combined)} samples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desd_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
